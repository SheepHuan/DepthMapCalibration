{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\klay\\Downloads\\mobile_tof-2\\calibration\\calibration\\data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m num \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m     13\u001b[0m     h,w,_ \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mshape\n\u001b[0;32m     14\u001b[0m     frame \u001b[39m=\u001b[39m frame[h\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,::]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 图像拍摄\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "save_dir = os.path.join(os.getcwd(),\"calibration\",\"data\")\n",
    "print(save_dir)\n",
    "num = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    h,w,_ = frame.shape\n",
    "    frame = frame[h-1::-1,::-1,::]\n",
    "    # for i in range(0,480,20):\n",
    "    #     cv2.line(frame,(0,i),(1280,i),(0,0,255),1)\n",
    "    cv2.imshow(\"A video\", frame)\n",
    "\n",
    "    c = cv2.waitKey(1)\n",
    "    # 按 Esc 退出\n",
    "    if c == 27:\n",
    "        break\n",
    "    # 按 g 拍摄\n",
    "    elif c == 32:\n",
    "        img_1 = frame[:,0:640,:]\n",
    "        img_2 = frame[:,640:1280,:]\n",
    "        num  = num + 1\n",
    "        name1 = f\"./data/imgL_{num}.png\"\n",
    "        name2 = f\"./data/imgR_{num}.png\"\n",
    "\n",
    "    \n",
    "        cv2.imwrite(name1,img_1)\n",
    "      \n",
    "        cv2.imwrite(name2,img_2)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_coefficients(mtx, dist, path):\n",
    "    \"\"\" Save the camera matrix and the distortion coefficients to given path/file. \"\"\"\n",
    "    cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_WRITE)\n",
    "    cv_file.write(\"K\", mtx)\n",
    "    cv_file.write(\"D\", dist)\n",
    "    # note you *release* you don't close() a FileStorage object\n",
    "    cv_file.release()\n",
    "\n",
    "\n",
    "def save_stereo_coefficients(path, K1, D1, K2, D2, R, T, E, F, R1=None, R2=None, P1=None, P2=None, Q=None):\n",
    "    \"\"\" Save the stereo coefficients to given path/file. \"\"\"\n",
    "    cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_WRITE)\n",
    "    cv_file.write(\"K1\", K1)\n",
    "    cv_file.write(\"D1\", D1)\n",
    "    cv_file.write(\"K2\", K2)\n",
    "    cv_file.write(\"D2\", D2)\n",
    "    cv_file.write(\"R\", R)\n",
    "    cv_file.write(\"T\", T)\n",
    "    cv_file.write(\"E\", E)\n",
    "    cv_file.write(\"F\", F)\n",
    "    cv_file.write(\"R1\", R1)\n",
    "    cv_file.write(\"R2\", R2)\n",
    "    cv_file.write(\"P1\", P1)\n",
    "    cv_file.write(\"P2\", P2)\n",
    "    cv_file.write(\"Q\", Q)\n",
    "    cv_file.release()\n",
    "\n",
    "\n",
    "def load_coefficients(path):\n",
    "    \"\"\" Loads camera matrix and distortion coefficients. \"\"\"\n",
    "    # FILE_STORAGE_READ\n",
    "    cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_READ)\n",
    "\n",
    "    # note we also have to specify the type to retrieve other wise we only get a\n",
    "    # FileNode object back instead of a matrix\n",
    "    camera_matrix = cv_file.getNode(\"K\").mat()\n",
    "    dist_matrix = cv_file.getNode(\"D\").mat()\n",
    "\n",
    "    cv_file.release()\n",
    "    return [camera_matrix, dist_matrix]\n",
    "\n",
    "\n",
    "def load_stereo_coefficients(path):\n",
    "    \"\"\" Loads stereo matrix coefficients. \"\"\"\n",
    "    # FILE_STORAGE_READ\n",
    "    cv_file = cv2.FileStorage(path, cv2.FILE_STORAGE_READ)\n",
    "\n",
    "    # note we also have to specify the type to retrieve other wise we only get a\n",
    "    # FileNode object back instead of a matrix\n",
    "    K1 = cv_file.getNode(\"K1\").mat()\n",
    "    D1 = cv_file.getNode(\"D1\").mat()\n",
    "    K2 = cv_file.getNode(\"K2\").mat()\n",
    "    D2 = cv_file.getNode(\"D2\").mat()\n",
    "    R = cv_file.getNode(\"R\").mat()\n",
    "    T = cv_file.getNode(\"T\").mat()\n",
    "    E = cv_file.getNode(\"E\").mat()\n",
    "    F = cv_file.getNode(\"F\").mat()\n",
    "    R1 = cv_file.getNode(\"R1\").mat()\n",
    "    R2 = cv_file.getNode(\"R2\").mat()\n",
    "    P1 = cv_file.getNode(\"P1\").mat()\n",
    "    P2 = cv_file.getNode(\"P2\").mat()\n",
    "    Q = cv_file.getNode(\"Q\").mat()\n",
    "\n",
    "    cv_file.release()\n",
    "    # return [K1, D1, K2, D2, R, T, E, F]\n",
    "    return [K1, D1, K2, D2, R, T, E, F, R1, R2, P1, P2, Q]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:01<00:00, 15.15it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 26.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# 单相机棋盘格标定\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.maxArea = 5e2\n",
    "params.minArea = 100\n",
    "params.minDistBetweenBlobs = 10\n",
    "\n",
    "blobDetector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "\n",
    "def calibrate(dirpath, prefix, image_format, square_size, width=9, height=6, board_type=\"chessboard\"):\n",
    "    \"\"\" Apply camera calibration operation for images in the given directory path. \"\"\"\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,6,0)\n",
    "    objp = np.zeros((height*width, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:width, 0:height].T.reshape(-1, 2)\n",
    "\n",
    "    objp = objp * square_size  # Create real world coords. Use your metric.\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    # Directory path correction. Remove the last character if it is '/'\n",
    "    if dirpath[-1:] == '/':\n",
    "        dirpath = dirpath[:-1]\n",
    "\n",
    "    # Get the images\n",
    "    images = glob.glob(dirpath+'/' + prefix + '*.' + image_format)\n",
    "\n",
    "    # Iterate through the pairs and find chessboard corners. Add them to arrays\n",
    "    # If openCV can't find the corners in an image, we discard the image.\n",
    "    for fname in tqdm(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        keypoints = blobDetector.detect(gray)\n",
    "        circle_img = img.copy()\n",
    "        for kp in keypoints:\n",
    "            cv2.circle(circle_img, (int(kp.pt[0]), int(kp.pt[1])), 5, (0, 0, 255), 3)\n",
    "        if board_type == \"chessboard\":\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (width, height), None)\n",
    "        elif board_type == \"circle\":\n",
    "            ret, corners = cv2.findCirclesGrid(gray, (width, height), cv2.CALIB_CB_ASYMMETRIC_GRID\n",
    "                , blobDetector, None)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{board_type} is not implemented\")\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "    flag = 0\n",
    "    flag |= cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "    flag |= cv2.CALIB_ZERO_TANGENT_DIST\n",
    "    # flag |= cv2.CALIB_FIX_K1\n",
    "    # flag |= cv2.CALIB_FIX_K2\n",
    "    flag |= cv2.CALIB_FIX_K3\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],np.asarray([0.,0.,0.,0.,0.]),flag)\n",
    "    # use distortion parameter\n",
    "    return ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "image_dir = \"./data_rs_stereo/\"\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate(image_dir,\"imgL\", \"png\", 0.35, 9, 6)\n",
    "save_coefficients(mtx, dist, \"stereo_R.yml\")\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate(image_dir,\"imgR\", \"png\", 0.35, 9, 6)\n",
    "save_coefficients(mtx, dist, \"rs.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 356 210 298\n",
      "156 356 210 299\n",
      "156 356 211 299\n",
      "156 356 211 300\n",
      "156 357 211 300\n",
      "157 357 211 300\n",
      "176 357 225 301\n",
      "176 357 225 301\n",
      "177 357 226 301\n",
      "177 377 226 314\n",
      "177 378 226 314\n",
      "177 378 226 314\n",
      "197 378 240 315\n",
      "197 378 240 315\n",
      "197 378 241 315\n",
      "197 378 241 316\n",
      "198 378 241 316\n",
      "198 378 242 316\n",
      "218 399 255 329\n",
      "218 399 256 329\n",
      "218 399 256 330\n",
      "218 399 256 330\n",
      "219 399 257 330\n",
      "219 399 257 330\n",
      "239 399 271 331\n",
      "239 399 271 331\n",
      "239 399 271 331\n",
      "239 420 271 344\n",
      "240 420 272 345\n",
      "240 420 272 345\n",
      "260 420 286 345\n",
      "260 420 286 345\n",
      "260 420 286 345\n",
      "261 421 287 346\n",
      "261 421 287 346\n",
      "261 421 288 346\n",
      "281 440 301 360\n",
      "282 441 302 360\n",
      "282 441 302 360\n",
      "282 441 302 360\n",
      "283 441 303 360\n",
      "283 442 303 361\n",
      "303 442 317 361\n",
      "304 443 317 361\n",
      "304 443 317 361\n",
      "304 461 318 375\n",
      "305 461 318 375\n",
      "305 462 319 375\n",
      "325 462 332 376\n",
      "326 463 333 376\n",
      "326 463 333 376\n",
      "327 464 333 376\n",
      "327 465 334 376\n",
      "327 465 334 376\n",
      "\n",
      "149 358 207 297\n",
      "150 358 207 297\n",
      "150 358 207 298\n",
      "151 358 207 298\n",
      "151 358 208 299\n",
      "152 358 208 300\n",
      "168 358 221 300\n",
      "168 358 221 301\n",
      "169 358 221 301\n",
      "169 379 222 314\n",
      "169 379 222 314\n",
      "170 380 222 314\n",
      "187 380 236 315\n",
      "187 381 236 315\n",
      "187 381 236 315\n",
      "188 382 236 316\n",
      "188 382 236 316\n",
      "188 383 236 316\n",
      "207 400 251 331\n",
      "207 401 251 331\n",
      "207 402 251 331\n",
      "207 402 251 331\n",
      "208 403 251 331\n",
      "208 404 251 331\n",
      "227 405 266 331\n",
      "227 406 266 331\n",
      "227 408 266 331\n",
      "227 421 266 347\n",
      "228 422 266 347\n",
      "228 423 266 347\n",
      "248 425 282 347\n",
      "248 426 282 347\n",
      "248 428 282 348\n",
      "248 429 282 348\n",
      "249 431 282 348\n",
      "249 432 282 348\n",
      "270 442 298 362\n",
      "270 444 298 362\n",
      "270 445 298 363\n",
      "270 447 298 363\n",
      "271 449 298 364\n",
      "271 451 298 364\n",
      "292 453 315 365\n",
      "293 455 315 365\n",
      "293 457 315 366\n",
      "293 463 315 377\n",
      "293 465 315 378\n",
      "293 467 315 379\n",
      "316 470 332 379\n",
      "317 472 332 380\n",
      "317 474 332 381\n",
      "317 477 332 382\n",
      "317 480 333 382\n",
      "317 482 333 383\n",
      "\n",
      "Stereo calibration rms:  0.1268352855348894\n"
     ]
    }
   ],
   "source": [
    "# 双目立体标定\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import glob\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.01)\n",
    "image_size = None\n",
    "\n",
    "def stereo_calibrate(left_file, right_file, left_dir, left_prefix, right_dir, right_prefix, image_format, save_file, square_size,\n",
    "        width=9, height=6):\n",
    "    \"\"\" Stereo calibration and rectification \"\"\"\n",
    "    objp, leftp, rightp = load_image_points(left_dir, left_prefix, right_dir, right_prefix, image_format,\n",
    "         square_size, width, height)\n",
    "\n",
    "    K1, D1 = load_coefficients(left_file)\n",
    "    K2, D2 = load_coefficients(right_file)\n",
    "    flag = 0\n",
    "    flag |= cv2.CALIB_ZERO_DISPARITY\n",
    "    flag |= cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "    flag |= cv2.CALIB_ZERO_TANGENT_DIST\n",
    "    # flag |= cv2.CALIB_FIX_K2\n",
    "    flag |= cv2.CALIB_FIX_K3\n",
    "    flag |= cv2.CALIB_FIX_K4\n",
    "    flag |= cv2.CALIB_FIX_K5\n",
    "    flag |= cv2.CALIB_FIX_K6\n",
    "\n",
    "    # flag |= cv2.CALIB_FIX_INTRINSIC\n",
    "    # flag |= cv2.CALIB_USE_INTRINSIC_GUESS\n",
    "    # flag |= cv2.CALIB_FIX_FOCAL_LENGTH\n",
    "    # flag |= cv2.CALIB_ZERO_TANGENT_DIST\n",
    "\n",
    "    ret, K1, D1, K2, D2, R, T, E, F = cv2.stereoCalibrate(objp, leftp, rightp, K1, D1, K2, D2, image_size,flags=flag,criteria=criteria)\n",
    "    print(\"Stereo calibration rms: \", ret)\n",
    "    # MARK: remove distortion\n",
    "    # D1 = D2 = np.asarray([0,0,0,0,0])\n",
    "\n",
    "    R1, R2, P1, P2, Q, roi_left, roi_right = cv2.stereoRectify(K1,D1, K2,D2, image_size, R, T, flags=cv2.CALIB_ZERO_DISPARITY)\n",
    "\n",
    "    # save_stereo_coefficients(save_file, K1, D1, K2, D2, R, T, E, F)\n",
    "    save_stereo_coefficients(save_file, K1, D1, K2, D2, R, T, E, F, R1, R2, P1, P2, Q)\n",
    "\n",
    "\n",
    "def load_image_points(left_dir, left_prefix, right_dir, right_prefix, image_format, square_size, width=9, height=6):\n",
    "    global image_size\n",
    "    pattern_size = (width, height)  # Chessboard size!\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,6,0)\n",
    "    objp = np.zeros((height * width, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:width, 0:height].T.reshape(-1, 2)\n",
    "\n",
    "    objp = objp * square_size  # Create real world coords. Use your metric.\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = []  # 3d point in real world space\n",
    "    left_imgpoints = []  # 2d points in image plane.\n",
    "    right_imgpoints = []  # 2d points in image plane.\n",
    "\n",
    "    # Left directory path correction. Remove the last character if it is '/'\n",
    "    if left_dir[-1:] == '/':\n",
    "        left_dir = left_dir[:-1]\n",
    "\n",
    "    # Right directory path correction. Remove the last character if it is '/'\n",
    "    if right_dir[-1:] == '/':\n",
    "        right_dir = right_dir[:-1]\n",
    "\n",
    "    # Get images for left and right directory. Since we use prefix and formats, both image set can be in the same dir.\n",
    "    left_images = glob.glob(left_dir + '/' + left_prefix + '*.' + image_format)\n",
    "    right_images = glob.glob(right_dir + '/' + right_prefix + '*.' + image_format)\n",
    "\n",
    "    # Images should be perfect pairs. Otherwise all the calibration will be false.\n",
    "    # Be sure that first cam and second cam images are correctly prefixed and numbers are ordered as pairs.\n",
    "    # Sort will fix the globs to make sure.\n",
    "    left_images.sort()\n",
    "    right_images.sort()\n",
    "\n",
    "    # Pairs should be same size. Otherwise we have sync problem.\n",
    "    if len(left_images) != len(right_images):\n",
    "        print(\"Numbers of left and right images are not equal. They should be pairs.\")\n",
    "        print(\"Left images count: \", len(left_images))\n",
    "        print(\"Right images count: \", len(right_images))\n",
    "        sys.exit(-1)\n",
    "\n",
    "    pair_images = zip(left_images, right_images)  # Pair the images for single loop handling\n",
    "\n",
    "    # Iterate through the pairs and find chessboard corners. Add them to arrays\n",
    "    # If openCV can't find the corners in one image, we discard the pair.\n",
    "    num = 0\n",
    "    for left_im, right_im in pair_images:\n",
    "        if num>1:\n",
    "            continue\n",
    "        num+=1\n",
    "        # Right Object Points\n",
    "        right = cv2.imread(right_im)\n",
    "        gray_right = cv2.cvtColor(right, cv2.COLOR_BGR2GRAY)\n",
    "        # Find the chess board corners\n",
    "        ret_right, corners_right = cv2.findChessboardCorners(gray_right, pattern_size,\n",
    "                                                             cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_FILTER_QUADS)\n",
    "        # Left Object Points\n",
    "        left = cv2.imread(left_im)\n",
    "        gray_left = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chess board corners\n",
    "        ret_left, corners_left = cv2.findChessboardCorners(gray_left, pattern_size,\n",
    "                                                           cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_FILTER_QUADS)\n",
    "\n",
    "        if ret_left and ret_right:  # If both image is okay. Otherwise we explain which pair has a problem and continue\n",
    "            # Object points\n",
    "            objpoints.append(objp)\n",
    "            # Right points\n",
    "            corners2_right = cv2.cornerSubPix(gray_right, corners_right, (5, 5), (-1, -1), criteria)\n",
    "            right_imgpoints.append(corners2_right)\n",
    "            # Left points\n",
    "            corners2_left = cv2.cornerSubPix(gray_left, corners_left, (5, 5), (-1, -1), criteria)\n",
    "            left_imgpoints.append(corners2_left)\n",
    "            l_c = np.asanyarray(corners_left).reshape([54,2])\n",
    "            r_c = np.asanyarray(corners_right).reshape([54,2])\n",
    "            l_c = np.sort(l_c,0)\n",
    "            l_c = np.sort(l_c,1)\n",
    "            r_c = np.sort(r_c,0)\n",
    "            r_c = np.sort(r_c,1)\n",
    "            l_c = np.round(l_c)\n",
    "            r_c = np.round(r_c)\n",
    "            l_c = l_c.astype(np.int32)\n",
    "            r_c = r_c.astype(np.int32)\n",
    "            res_s = \"\"\n",
    "            for i in range(54):\n",
    "                res_s = res_s + f\"{l_c[i][0]} {l_c[i][1]} {r_c[i][0]} {r_c[i][1]}\\n\"\n",
    "            \n",
    "            print(res_s)\n",
    "            open(\"C:/Users/klay/Downloads/mobile_tof-2/calibration/mathc.txt\",'w').write(res_s)\n",
    "            # print(corners2_left[:][0],corners2_right[:][0])\n",
    "        else:\n",
    "            print(\"Chessboard couldn't detected. Image pair: \", left_im, \" and \", right_im)\n",
    "            continue\n",
    "\n",
    "    # print(left_imgpoints[0][0][0])\n",
    "    image_size = gray_right.shape  # If you have no acceptable pair, you may have an error here.\n",
    "    return [objpoints, left_imgpoints, right_imgpoints]\n",
    "\n",
    "left_yml_file = \"C:/Users/klay/Downloads/mobile_tof-2/calibration/stereo_R.yml\"\n",
    "right_yml_file = r\"C:\\\\Users\\\\klay\\Downloads\\\\mobile_tof-2\\\\calibration\\\\rs.yml\"\n",
    "right_img_dir  = \"C:\\\\Users\\\\klay\\\\Downloads\\\\mobile_tof-2\\\\calibration\\\\data_rs_stereo\"\n",
    "left_img_dir = \"C:\\\\Users\\\\klay\\\\Downloads\\\\mobile_tof-2\\\\calibration\\\\data_rs_stereo\"\n",
    "save_file = \"C:\\\\Users\\\\klay\\\\Downloads\\\\mobile_tof-2\\\\calibration\\\\stereo_rs.yml\"\n",
    "stereo_calibrate(left_yml_file, right_yml_file, left_img_dir, \"imgL\", right_img_dir,\"imgR\", \"png\", save_file, 0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 深度图获取\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "def get_disparity_map(imgL, imgR):\n",
    "    window_size = 7  # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "    left_matcher = cv2.StereoSGBM_create(\n",
    "        minDisparity=0,\n",
    "        numDisparities= 10*16,  # max_disp has to be dividable by 16 f. E. HH 192, 256\n",
    "        blockSize=window_size,\n",
    "        P1=8 * 3 * window_size ,\n",
    "        # wsize default 3; 5; 7 for SGBM reduced size image; 15 for SGBM full size image (1300px and above); 5 Works nicely\n",
    "        P2=32 * 3 * window_size,\n",
    "        disp12MaxDiff=7,\n",
    "        uniquenessRatio=10,\n",
    "        speckleWindowSize=50,\n",
    "        speckleRange=32,\n",
    "        preFilterCap=63,\n",
    "        mode=cv2.STEREO_SGBM_MODE_HH4\n",
    "    )\n",
    "    right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "    # FILTER Parameters\n",
    "    lmbda = 80000\n",
    "    sigma = 1.3\n",
    "    visual_multiplier = 6\n",
    "\n",
    "    wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)\n",
    "    wls_filter.setLambda(lmbda)\n",
    "\n",
    "    wls_filter.setSigmaColor(sigma)\n",
    "    displ = left_matcher.compute(imgL, imgR)  # .astype(np.float32)/16\n",
    "    dispr = right_matcher.compute(imgR, imgL)  # .astype(np.float32)/16\n",
    "    displ = np.int16(displ)\n",
    "    dispr = np.int16(dispr)\n",
    "    filteredImg = wls_filter.filter(displ, imgL, None, dispr)  # important to put \"imgL\" here!!!\n",
    "    unnormalized_filteredImg = copy.deepcopy(filteredImg)\n",
    "    filteredImg = np.clip(filteredImg,0,None)\n",
    "    filteredImg = cv2.normalize(src=filteredImg, dst=filteredImg, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX)\n",
    "    filteredImg = np.uint8(filteredImg)\n",
    "\n",
    "    return unnormalized_filteredImg,filteredImg\n",
    "\n",
    "\n",
    "stereo_calibration_file = \"C:\\\\Users\\\\klay\\\\Downloads\\\\mobile_tof-2\\\\calibration\\\\stereo_rs.yml\"\n",
    "\n",
    "K1, D1, K2, D2, R, T, E, F, R1, R2, P1, P2, Q = load_stereo_coefficients(stereo_calibration_file)\n",
    "left_dir = \"C:\\\\Users\\\\klay\\\\Downloads\\\\mobile_tof-2\\\\calibration\\\\data_rs_stereo\"\n",
    "right_dir = \"C:\\\\Users\\\\klay\\\\Downloads\\\\mobile_tof-2\\\\calibration\\\\data_rs_stereo\"\n",
    "\n",
    "left_images_path = glob.glob(left_dir + \"/imgL*.png\")\n",
    "right_images_path = glob.glob(right_dir + \"/imgR*.png\")\n",
    "\n",
    "\n",
    "for i,left_image_path in enumerate(left_images_path[:]):\n",
    "    right_image_path = right_images_path[i]\n",
    "    left_image  = cv2.imread(left_image_path)\n",
    "    right_image = cv2.imread(right_image_path)\n",
    "\n",
    "    height, width, channel = left_image.shape  # We will use the shape for remap\n",
    "\n",
    "    # 校正图像\n",
    "    leftMapX, leftMapY = cv2.initUndistortRectifyMap(K1, D1, R1, P1, (width, height), cv2.CV_32FC1)\n",
    "    rightMapX, rightMapY = cv2.initUndistortRectifyMap(K2, D2, R2, P2, (width, height), cv2.CV_32FC1)\n",
    "    left_rectified = cv2.remap(left_image, leftMapX, leftMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "    right_rectified = cv2.remap(right_image, rightMapX, rightMapY, cv2.INTER_LINEAR, cv2.BORDER_CONSTANT)\n",
    "    gray_left = cv2.cvtColor(left_rectified, cv2.COLOR_BGR2GRAY)\n",
    "    gray_right = cv2.cvtColor(right_rectified, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"t\",np.hstack([left_rectified,right_rectified]))\n",
    "    unnormalized_disparity_image,normalized_disparity_image = get_disparity_map(gray_left, gray_right)  # Get the disparity map\n",
    "    # unnormalized_disparity_image = np.clip(unnormalized_disparity_image,0,None)\n",
    "    # 视差图投影到3D xyz\n",
    "    unnormalized_disparity_image = unnormalized_disparity_image.astype(np.float32) / 16\n",
    "    points_3d = cv2.reprojectImageTo3D(unnormalized_disparity_image, Q)\n",
    "\n",
    "    # 过滤z轴坐标值,最大值不超过6\n",
    "    depth_map = points_3d[:, :, -1]\n",
    "    unnormalized_depth_map = depth_map.copy()\n",
    "    # depth_map = np.clip(depth_map, -10, 0)\n",
    "    depth_map = np.clip(depth_map, 0, 10)\n",
    "    # print(min(depth_map))\n",
    "\n",
    "    filename = left_image_path.split(\"\\\\\")[-1]\n",
    "    depth_map = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    # depth_map = depth_map.astype(np.uint8)\n",
    "    depth_map = 255 - depth_map\n",
    "    depth_map = cv2.applyColorMap(depth_map, cv2.COLORMAP_MAGMA)\n",
    "\n",
    "    # stereo_pair = np.hstack([left_rectified, right_rectified])\n",
    "    # h, w = stereo_pair.shape[0:2]\n",
    "    # num_lines = 20\n",
    "    # for i in range(num_lines):\n",
    "    #     cv2.line(stereo_pair, (0, h * i // num_lines), (w, h * i // num_lines), (0, 0, 255), 1)\n",
    "    # cv2.imshow(\"depth\",depth_map)\n",
    "    cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
